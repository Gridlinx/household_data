{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fdd7071a-0bcf-48c5-9ed7-772ab69e59df"
    }
   },
   "source": [
    "<table style=\"width:100%; background-color: #EBF5FB\">\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #CFCFCF\">\n",
    "      <b>Household data: Processing Notebook</b>\n",
    "      <ul>\n",
    "        <li><a href=\"main.ipynb\">Main Notebook</a></li>\n",
    "        <li>Processing Notebook</li>\n",
    "      </ul>\n",
    "      <br>This Notebook is part of the <a href=\"http://data.open-power-system-data.org/household_data\">Household Data Package</a> of <a href=\"http://open-power-system-data.org\">Open Power System Data</a>.\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Introductory Notes](#1.-Introductory-Notes)\n",
    "* [2. Settings](#2.-Settings)\n",
    "\t* [2.1 Import Python libraries](#2.1-Import-Python-libraries)\n",
    "\t* [2.2 Set version number and recent changes](#2.2-Set-version-number-and-recent-changes)\n",
    "\t* [2.3 Select timerange](#2.3-Select-timerange)\n",
    "\t* [2.4 Select download source](#2.4-Select-download-source)\n",
    "* [3. Download](#3.-Download)\n",
    "* [4. Read](#4.-Read)\n",
    "\t* [4.1 Preparations](#4.1-Preparations)\n",
    "\t* [4.2 Select household subset](#4.2-Select-household-subset)\n",
    "\t* [4.3 Reading loop](#4.3-Reading-loop)\n",
    "\t* [4.4 Save raw data](#4.4-Save-raw-data)\n",
    "* [5. Processing](#5.-Processing)\n",
    "\t* [5.1 Validate Data](#5.1-Validate-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bba7a58e-f3b2-4d3b-9617-d734c369084f"
    }
   },
   "source": [
    "# 1. Introductory Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook handles missing data, performs calculations and aggragations and creates the output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ba6b62da-6cee-476b-a563-c945f3fd0f79"
    }
   },
   "source": [
    "# 2. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2b838df4-f987-4ae4-a132-9c898e3ffab1"
    }
   },
   "source": [
    "## 2.1 Import Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d4e82608-1ad1-4c51-8285-929a5a92c5b6"
    }
   },
   "source": [
    "This section: load libraries and set up a log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "init_cell": true,
    "nbpresent": {
     "id": "c0035fc6-ff1d-44d8-a3fd-b4c08f53be71"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Python modules\n",
    "from datetime import datetime, date, timedelta, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import sqlite3\n",
    "import yaml\n",
    "import itertools\n",
    "import os\n",
    "import pytz\n",
    "import hashlib\n",
    "from shutil import copyfile\n",
    "\n",
    "# Scripts from household repository package\n",
    "from household.download import download\n",
    "from household.read import read\n",
    "from household.validation import validate\n",
    "\n",
    "# Reload modules with execution of any code, to avoid having to restart\n",
    "# the kernel after editing timeseries_scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "households_yaml_path = 'input/households.yml'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('log')\n",
    "# For more detailed logging messages, replace 'INFO' with 'DEBUG'\n",
    "# (May slow down computation).\n",
    "#logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Set version number and recent changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this script till the end will create a new version of the data package.\n",
    "The Version number specifies the local directory for the data <br>\n",
    "We include a note on what has been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "version = '2017-06-30'\n",
    "data_path = os.path.join(version, 'original_data')\n",
    "changes = '''Initial upload'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Select timerange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the time range to read and process data. <br>\n",
    "*Default: all data.*\n",
    "\n",
    "Type `None` to process all available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_from_user = None  # i.e. date(2016, 1, 1)\n",
    "end_from_user = None  # i.e. date(2016, 1, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Select download source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data can be downloaded as a zip file from the OPSD Server. To do this, specify an archive version to use, that has been cached on the OPSD server as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "archive_version = '2017-06-30' # i.e. '2017-06-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section: download raw data to process.\n",
    "\n",
    "If the original data does not exist, it will be downloaded from the OPSD Server and extracted in a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "format": "row",
    "nbpresent": {
     "id": "0c1eb987-6d5f-4e3d-9248-df80b9f37a49"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:log:original_data.zip already exists. Delete it if you want to download again\n",
      "INFO:log:Extracted data to /original_data.\n"
     ]
    }
   ],
   "source": [
    "download(version=archive_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d0b353e7-179d-4556-bdd2-270192c830fb"
    }
   },
   "source": [
    "# 4. Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d223207e-2b0e-49ec-8bf6-af2969ee5b28"
    }
   },
   "source": [
    "This section: Read each downloaded file into a pandas-DataFrame and merge data from different sources if it has the same time resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1300cbb2-efde-4844-b08c-fed092023e38"
    }
   },
   "source": [
    "Set the title of the rows at the top of the data used to store metadata internally. The order of this list determines the order of the levels in the resulting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "format": "row",
    "init_cell": true,
    "nbpresent": {
     "id": "4dc92cc3-c01d-4c83-9252-80958edbe0f9"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "headers = ['project', 'region', 'household', 'type', 'feed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty dictionary to be populated by the read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_households = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Select household subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, specify a subset of households to process. <br>\n",
    "The next cell prints the available sources and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residential 4:\n",
      "- grid_import\n",
      "- grid_export\n",
      "- pv\n",
      "- ev\n",
      "- heat_pump\n",
      "- dishwasher\n",
      "- washing_machine\n",
      "- refrigerator\n",
      "- freezer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(households_yaml_path, 'r') as f:\n",
    "    households = yaml.load(f.read())\n",
    "for k, v in households.items():\n",
    "    print(yaml.dump({k: list(v['feeds'].keys())}, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy from its output and paste to following cell to get the right format.\n",
    "\n",
    "Type `subset = None` to include all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = yaml.load('''\n",
    "    insert_household_here:\n",
    "    - insert_feed1_here\n",
    "    - insert_feed2_here\n",
    "    more_households_here:\n",
    "    - more_feeds_here\n",
    "    ''')\n",
    "\n",
    "subset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now eliminate households and feeds not in subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if subset:  # eliminate households and feeds not in subset\n",
    "    households = {household_name: {k: v\n",
    "                                   for k, v in households[household_name].items()\n",
    "                                   for k, v in households[household_name]['feeds'].items()\n",
    "                                   if k in feed_list}\n",
    "                  for household_name, feed_list in subset.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Reading loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through households and feeds to do the reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:log:Reading Residential 4 - feeds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 9/9 feeds Done...\n"
     ]
    }
   ],
   "source": [
    "# For each source in the household dictionary\n",
    "for household_name, household_dict in households.items():\n",
    "    df = read(household_name, household_dict['dir'], household_dict['feeds'], \n",
    "              household_dict['project'], household_dict['region'], household_dict['type'], headers, \n",
    "              start_from_user=start_from_user,\n",
    "              end_from_user=end_from_user)\n",
    "    \n",
    "    data_households[household_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Save raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the DataFrames created by the read function to disk. This way you have the raw data to fall back to if something goes wrong in the remainder of this notebook without having to repeat the previos steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for household_name, household_dict in households.items():\n",
    "    data_households[household_name].to_pickle('raw_'+household_dict['dir']+'.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the DataFrames saved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_households = {}\n",
    "for household_name, household_dict in households.items():\n",
    "    data_households[household_name] = pd.read_pickle('raw_'+household_dict['dir']+'.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section: validate energy data and fix wrongly measured data points. Handle missing data and aggregation to regular and 15 minute intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Validate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the raw data being the unvalidated measurements of a research prototype under development, certain steps should be taken, to remove clearly incorrect measured data points or react to other events, such as the counter reset of an energy meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:log:Validate Residential 4 - feeds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################################################] 9/9 feeds Done...\n"
     ]
    }
   ],
   "source": [
    "data_sets = {'1min': pd.DataFrame(), '3min': pd.DataFrame(), '15min': pd.DataFrame()}\n",
    "for household_name, household_dict in households.items():\n",
    "    data_households[household_name] = validate(household_name, household_dict['dir'], \n",
    "                                               household_dict['feeds'], household_dict['adjustments'], \n",
    "                                               data_households[household_name], output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Initialisation Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {
    "f6b300bf-88b5-4dea-951e-c926a9ea8287": {
     "id": "f6b300bf-88b5-4dea-951e-c926a9ea8287",
     "prev": "f96dd4bc-93a6-4014-b85f-a43061cf5688",
     "regions": {
      "dc486e18-7547-4610-99c0-55dfb5553f62": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "c0035fc6-ff1d-44d8-a3fd-b4c08f53be71",
        "part": "source"
       },
       "id": "dc486e18-7547-4610-99c0-55dfb5553f62"
      }
     }
    },
    "f96dd4bc-93a6-4014-b85f-a43061cf5688": {
     "id": "f96dd4bc-93a6-4014-b85f-a43061cf5688",
     "prev": null,
     "regions": {
      "657c3ad3-2fcf-4c8e-a527-de3d0a46fa4e": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "1562965a-7d74-4c1c-8251-4d82847f294a",
        "part": "source"
       },
       "id": "657c3ad3-2fcf-4c8e-a527-de3d0a46fa4e"
      }
     }
    }
   },
   "themes": {}
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
